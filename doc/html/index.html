<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Theory of Mind + Abduction: tomabd documentation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "amssymb.js", "amsmath.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Theory of Mind + Abduction
   </div>
   <div id="projectbrief">A Jason agent combining Theory of Mind with abductive reasoning</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">tomabd documentation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This package provides a <a href="http://jason.sourceforge.net">Jason</a> agent that combines Theory of Mind and abductive reasoning to interpret and extract information from the actions of other agents.</p>
<p>The main class of this package is <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html">tomabd.agent.TomAbdAgent</a>, since it contains the methods that implement the actual computations. Other classes in the <a class="el" href="namespacetomabd_1_1agent.html">tomabd.agent</a> package are <a href="http://jason.sourceforge.net/api/jason/stdlib/package-summary.html">Jason internal actions</a> (IAs) that provide an interface to the public methods of the <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html">tomabd.agent.TomAbdAgent</a> class that are most likely to be invoked from the AgentSpeak code. Other IAs in the <a class="el" href="namespacetomabd_1_1misc.html">tomabd.misc</a> package provide manipulations of AgentSpeak constructs, such as literals, logical formulas and Prolog-like rules. These are particularly handy for writing the Theory of Mind clauses with head <code>knows(Ag, Fact)</code> (see <a class="el" href="index.html#viewpoint">Adopting a different viewpoint</a>).</p>
<dl class="section author"><dt>Author</dt><dd>Nieves Montes</dd></dl>
<h1><a class="anchor" id="model"></a>
Agent model</h1>
<p>For an example to help understand the discussion that follows, the reader is directed to the <a href="...">examples folder</a>.</p>
<p>The agent model that this package implements revolves around <b>Theory of Mind + abduction (Tom+Abd) task</b>. One task is composed of roughly these steps:</p><ol type="1">
<li>Adopt the <ins>acting agent viewpoint</ins>.</li>
<li>Generate abductive explanations.</li>
<li>Refine abductive explanations from the acting agent viewpoint.</li>
<li>Adopt the <ins>observer agent viewpoint</ins>.</li>
<li>Refine abductive explanations from the observer agent viewpoint.</li>
</ol>
<p>Steps 1 and 4 are covered in <a class="el" href="index.html#viewpoint">Adopting a different viewpoint</a>. Steps 2, and 3 and 5 are covered in abduction.</p>
<p>To set the scene, consider the following:</p><ul>
<li>Agent \(i\) operating with logic program \(T_i\). refer to agent \(i\) as the <b>observer agent</b>. Agent \(i\) will be the one performing a ToM+Abd task.</li>
<li>Agent \(j\), operating with logic program \(T_j\). We refer to agent \(j\) as the <b>actor</b> or <b>acting agent</b>.</li>
</ul>
<p>In BDI terms, the agents' logic programs correspond to their belief bases, i.e. a set of symbolic facts and rules.</p>
<p>An underlying assumption of this agent model is that agents select their actions according to a set of <b>action selection clauses</b>. This is a set of Prolog-like rules: <code>action(Agent, Action) :- ...</code> . These clauses indicate what action should be taken by every agent given their current perception of the system. These clauses are necessary because actions are the queries that need to be explained by the abductive reasoning process (see <a class="el" href="index.html#abduction">Generating and refining abductive explanations</a>).</p>
<h2><a class="anchor" id="viewpoint"></a>
Adopting a different viewpoint</h2>
<p>At some time-step, the acting agent \(j\) selects an action \(a_j\) to be executed. Observer agent \(i\) comes to learn that \(j\) has indeed selected \(a_j\). The particular mechanism by which this happens is left as a domain-specific choice for the developer (see <a class="el" href="index.html#usage">Usage</a> section).</p>
<p><b>Note:</b> The action \(a_j\) <em>does not necessarily correspond to an agent action on the environment</em>. It can also be, for example, an achievement goal that is pursued by a plan composed of several atomic actions on the environment. Whichever way \(a_j\) is actually implemented is left as a domain-specific choice to be made by the MAS developer.</p>
<p>When \(i\) learns about \(j\)'s action choice, \(i\) seeks to <em>understand</em> the reasons and motivations behind this decision. To do so, \(i\) embarks on a <b>ToM+Abd task</b>.</p>
<p>First, \(i\) engages in Theory of Mind and substitutes its view of the world by <em>the view that it estimates \(j\) has of the world</em>. By doing so, the observer agent \(i\) is putting itself in the shoes of the acting agent \(j\). Computationally, \(i\) substitutes its program \(T_i\) by the program it <em>estimates that \(j\) is operating with</em>. We denote \(i\)'s estimation of \(j\)'s program by \(T_{i,j}\). \(T_{i,j}\) is computed as follows: </p><p class="formulaDsp">
\begin{equation} T_{i,j} = \{\phi \mid T_{i} \models \texttt{knows}(j, \phi)\} \label{eq:tom} \end{equation}
</p>
<p>Note that eq. \(\eqref{eq:tom}\) makes a reference to a <code>knows/2</code> predicate. These predicates are specified in a component of the agents' program known as <em>Theory of Mind (ToM) clauses</em>. These clauses specify what the <em>agent knows about what other agents know</em>, hence they have head <code>knows(Agent, Fact)</code>. ToM clauses are domain-specific rules and they are queried to build an approximation of other agent's programs. Hence, they operate as a meta-interpreter on the program \(T_i\) of the agent performing the ToM+Abd task.</p>
<p>Eq. \(\eqref{eq:tom}\) formulates <em>first-order</em> Theory of Mind. This means that agent \(i\) tries to view the world the way that it thinks \(j\) is perceiving it. However, eq. \(\eqref{eq:tom}\) can be recursively extended to any arbitrary level of Theory of Mind: </p><p class="formulaDsp">
\begin{equation} T_{i,k, ..., l, j} = \{\phi \mid T_{i, k, ..., l} \models \texttt{knows}(j, \phi)\} \label{eq:tom-recursion} \end{equation}
</p>
<p>For example, \(i\) might want to know how \(j\) is estimating that \(k\) is perceiving the world. This corresponds to \(T_{i,j,k}\), a <em>second-order</em> Theory of Mind substitution. In particular, it might be the case that \(i\) wants to know how \(j\) is estimating its own ( \(i\)'s) view. This corresponds to \(T_{i,j,i}\).</p>
<p>For the discussion that follows, we use the following notation in reference to the symbols in \(\eqref{eq:tom-recursion}\):</p><ul>
<li>The sequence \([k, ..., l, j]\) is the <em>actor viewpoint</em> (excluding the first index of the original agent \(i\)).</li>
<li>The last element of the sequence ( \(j\)) is the <em>acting agent</em>.</li>
<li>The sequence excluding the last element (the actor), \([j, ..., k]\), is the <em>observer viewpoint</em>.</li>
</ul>
<p>In order for the observer agent \(i\) to interpret tha acting agent \(j\)'s action, \(i\) needs to switch its perspective to that of the agent. This may mean adopting its direct estimation of \(j\)'s program ( \(T_{i,j}\)) in a <b>first-order</b> ToM+abd task, or through several intermediaries ( \(T_{i,k, ..., l, j}\)) in a <b>higher-order</b> ToM+abd task. Either way, the substitution of the original agent program by a new (arbitrary) viewpoint is implemented by the <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html#ae255adbec7b800ceac1028f2c7b89d7b">tomabd.agent.TomAbdAgent.adoptViewpoint</a> method.</p>
<h2><a class="anchor" id="abduction"></a>
Generating and refining abductive explanations</h2>
<p>Once observer \(i\) has adopted acting agent viewpoint, the observer is in a position to <em>explain</em> why the actor selected action \(a_j\), in hopes that this newly derived knowledge will be useful for his own later decision-making. This <em>inference to the best explanation</em> is called <b>abductive reasoning</b>. In order to compute abductive explanations, it is necessary to specify, in a domain-specific way the set of <b>abducible facts</b>. These are the facts that can possibly compliment a belief base. These are specified through a set of clauses with head <code>abducible(Fact)</code>.</p>
<p>The <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html">tomabd.agent.TomAbdAgent</a> class automatically loads an abductive meta-interpreter. Given query \(Q = \texttt{action}(j, a_j)\), the abductive meta-interpreter generates a set of <em>raw explanations</em> \(\Phi\), composed of <em>ground</em> abducible facts. This set of raw explanations can be represented in <em>disjunctive normal form</em> (DNF): </p><p class="formulaDsp">
\begin{equation} \Phi = (\phi_{11} \; \land \; ... \; \land \; \phi_{1n_1}) \; \lor \; ... \; \lor \; (\phi_{m1} \; \land \; ... \; \land \; \phi_{mn_m}) \label{eq:dnf} \end{equation}
</p>
<p> where all \(\phi_{rs}\) are derivable from the current belief base, i.e. \(T_{i, k, ..., l, j} \models \texttt{abducible}(\phi_{rs})\). Within the agent class, this DNF is implemented as a list of lists.</p>
<p>The raw explanations \(\Phi\) need to be <em>refined</em>, first of all, with respect to the viewpoint of the acting agent (i.e. the viewpoint from which they were generated in the first place). This steps allos the opportunity to further modify the raw abductive explanations to, for example, check for inconsistencies with respect to the current agent program \(T_{i,j,...,k,l}\). This <b>explanation refinement step</b> is implemented by the method <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html#afc4ca0d2ca0d89cc41503662dd73ff97">tomabd.agent.TomAbdAgent.erf</a>. The default computation performs the two following refinement steps:</p><ol type="1">
<li>First, for every potential explanation (i.e. every disjunct in \(\eqref{eq:dnf}\)), uninformative atoms are removed.</li>
<li>Second, disjuncts that are incompatible with the <em>impossibility constraints</em> in the current program \(T_{i,j,...,k,l}\) (i.e. at the acting agent viewpoint) are removed.</li>
</ol>
<p>The refined explanations with respect to the observer viewpoint are denoted by \(\Phi^{obs}\): </p><p class="formulaDsp">
\begin{equation} \Phi^{obs} = (\phi_{11}&#39; \; \land \; ... \; \land \; \phi_{1n_1&#39;}&#39;) \; \lor \; ... \; \lor \; (\phi_{m&#39;1}&#39; \; \land \; ... \; \land \; \phi_{m&#39;n_{m&#39;}&#39;}&#39;) \end{equation}
</p>
<p>The refined abductive explanation has to hold true. Consequently, <b>its negation must be false</b>. We take advantage of this statement to integrate the \(\Phi^{Obs}\) into the agent program, as logical formulas cannot be added to a Jason knowledge base, only ground literals. From the negation of \(\Phi^{Obs}\), we build a new <em>impossibility constraint</em> (IC): </p><p class="formulaDsp">
\begin{equation} \texttt{imp [source(abduction)] :- } (\sim\phi_{11}&#39; \; \texttt{|} \; ... \; \texttt{|} \; \sim\phi_{1n_1&#39;}&#39;) \; \texttt{&amp;} \; ... \; \texttt{&amp;} \; (\sim\phi_{m&#39;1}&#39; \; \texttt{|} \; ... \; \texttt{|} \; \sim\phi_{m&#39;n_{m&#39;}&#39;}&#39;). \label{eq:ic-actor} \end{equation}
</p>
<p>Note the <code>source(abduction)</code> annotation to indicate that this IC is derived from an abductive reasoning process and is <em>not</em> a domain-dependent IC.</p>
<p>However, eq. \(\eqref{eq:ic-actor}\) cannot be directly added to the original agent's program \(T_i\). Some extra step has to account for the fact that this explanation has been generated from viewpoint \([k, l, ..., j]\). To achieve this, the following <code>knows/2</code> is recursively built: </p><p class="formulaDsp">
\begin{equation} \texttt{knows($k$, ..., knows($l$, knows($j$, imp [source(abduction)] :- ... )) ... )} \end{equation}
</p>
<p>This literal is then added to the program of the original agent \(i\), \(T_{i}\).</p>
<p>This process allows to update the original agent's ( \(i\)'s) model of the actor viewpoint. However, the ultimate goal is to update the model of the world from the perspective of the <em>observer</em>. To do so, the whole process of (i) refining the raw explanations; (ii) building the abductive impossibility constraint; and (iii) building a new <code>knows/2</code> literal, is repeated, this time from the viewpoint of the <em>observer</em> agent. In case the viewpoint of the observer corresponds directly to the original agent \(i\) (which happens if the Theory of Mind task is first-order), the impossibility constraint of the form in eq. \(\eqref{eq:ic-actor}\) is directly added to \(T_i\).</p>
<h2><a class="anchor" id="euf"></a>
Updating abductive explanation</h2>
<p>Abductive explanation, once generated, will not be valid <em>forever</em>. Therefore, the <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html">tomabd.agent.TomAbdAgent</a> has a custom belief update function that includes a call to te <b>explanation update function</b> (euf). The default implementation follows these steps:</p><ol type="1">
<li>Update the belief base according to <code>buf()</code>.</li>
<li>For every literal originated in an abductive reasoning process (annotated with <code>source(abduction)</code>):<ol type="a">
<li>Extract the <em>viewpoint</em> at which it was generated and the associated explanation.</li>
<li>Adopt the <em>viewpoint</em> in question.</li>
<li>If the associated explanation can now be derived from the current program, drop the abductive literal from \(T_i\), since it is no longer informative.</li>
</ol>
</li>
</ol>
<p>This default explanation update function is implemented in the <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html#a30ec38dd1bf80132356572011a691e10">tomabd.agent.TomAbdAgent.euf</a> method, and can be overridden by the MAS developer in a custom subclass.</p>
<h2><a class="anchor" id="action-selection"></a>
Action selection</h2>
<p>The whole purpose of the ToM+Abd task is to have the observer agent \(i\) in a <em>better informed position</em> when it is \(i\)'s turn to act, thanks to the additional knowledge contained in the abductive ICs. Hence, this package also implements a basic action selection function that takes into account impossibility constraints derived from previous abduction tasks. The default implementation uses all ICs (abductive and domain-specific) to perform <em>possible worlds reasoning</em>. When querying the action selection rules, the interpreter may come across a sub-goal that, according to \(T_i\), is <em>abducible</em>. Then, the action selection function looks for all the possible instantiations of this abducible sub-goal. If all of the possible instantiations lead to the same being selected, that action is returned. This is a fairly restrictive action selection mechanisms, however it can be overridden by the MAS developer easily.</p>
<p>This default action selection is implemented in the agent method <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html#a0c75277f5b2895c484e9c5bef7d1d47d">tomabd.agent.TomAbdAgent.selectAction</a>. The internal action <a class="el" href="classtomabd_1_1agent_1_1select__action.html">tomabd.agent.select_action</a> is an interface to this method, so that it can be called from the AgentSpeak code (see the following section).</p>
<h1><a class="anchor" id="usage"></a>
Usage</h1>
<p>This package should be used in multi-agent systems developed using <a href="http://jason.sourceforge.net">Jason</a>. It is also compatible with <a href="http://jacamo.sourceforge.net">JaCaMo</a> (since JaCaMo is an integration of Jason with other agent-oriented programming tools). The recommended way to use this package is to download a copy of the jar file and add it to your project's class-path.</p>
<p>In Jason (.mas2j file): </p><div class="fragment"><div class="line">MAS myMAS {</div>
<div class="line"> </div>
<div class="line">     agents: ...</div>
<div class="line">     </div>
<div class="line">     environment: ...</div>
<div class="line"> </div>
<div class="line">     classpath: &quot;path/to/tomabd.jar&quot;;</div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p>In JaCaMo (.jcm file): </p><div class="fragment"><div class="line">mas myMAS {</div>
<div class="line"> </div>
<div class="line">     // agents configuration</div>
<div class="line">     ...</div>
<div class="line">     </div>
<div class="line">     // environment configuration</div>
<div class="line">     ...</div>
<div class="line"> </div>
<div class="line">     // organizations configuration</div>
<div class="line">     ...</div>
<div class="line"> </div>
<div class="line">     // execution configuration</div>
<div class="line">     class-path: path/to/tomabd.jar</div>
<div class="line">     ...</div>
<div class="line">     </div>
<div class="line">}</div>
</div><!-- fragment --><p>To trigger a Theory of Mind plus abduction task from the AgentSpeak code, invoke the internal action <a class="el" href="classtomabd_1_1agent_1_1tom__abduction__task.html">tomabd.agent.tom_abduction_task</a> : </p><div class="fragment"><div class="line">+!g : c</div>
<div class="line">     &lt;- ...;</div>
<div class="line">     tomabd.agent.tom_abduction_task(</div>
<div class="line">         ObserverViewpoint,               // a list</div>
<div class="line">         ActingAgent,                     // an atom</div>
<div class="line">         Action,                          // an atom</div>
<div class="line">         ActorViewpointExplanation,       // a variable that is bound by the IA</div>
<div class="line">         ObserverViewpointExplanations    // a variable that is bound by the IA</div>
<div class="line">     );</div>
<div class="line">     ...</div>
</div><!-- fragment --><p>The decision on when to invoke this IA is domain-specific and is left to the MAS developer. For example, in the Hanabi game a custom KQML performative <code>publicAction</code> is used to announce the selected action. A reception of a message with this performative triggers a Theory of Mind &ndash; abduction task: </p><div class="fragment"><div class="line">!kqml_received(KQML_Sender_Var, publicAction, Action, KQML_MsgId)</div>
<div class="line">     &lt;- ...</div>
<div class="line">     // first-order Theory of Mind -- abduction task</div>
<div class="line">     tomabd.agent.tom_abduction_task(</div>
<div class="line">         [], KQML_Sender_Var, Action, ActExpls, ObsExpls</div>
<div class="line">     );</div>
<div class="line">     ...</div>
</div><!-- fragment --><p>If one wishes to use the <a class="el" href="classtomabd_1_1agent_1_1TomAbdAgent.html#a0c75277f5b2895c484e9c5bef7d1d47d">tomabd.agent.TomAbdAgent.selectAction</a> method to select some or all of an agent's actions or goals to achieve next, the IA <a class="el" href="classtomabd_1_1agent_1_1select__action.html">tomabd.agent.select_action</a> acts as an interface to this method. Its usage is as follows: </p><div class="fragment"><div class="line">+!g : c</div>
<div class="line">     &lt;- ...;</div>
<div class="line">     tomabd.agent.select_action(</div>
<div class="line">         Action,         // a variable that is bound by the IA</div>
<div class="line">         Priority        // a variable that is bound by the IA</div>
<div class="line">     );</div>
<div class="line">     ...;</div>
<div class="line">     Action;             // if the action is modelled as an action on the environment, or</div>
<div class="line">     !Action;            // if the action is modelled as an achievement goal</div>
<div class="line">     ...</div>
</div><!-- fragment --> </div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed Jul 20 2022 10:18:12 for Theory of Mind + Abduction by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
